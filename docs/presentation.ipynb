{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed58ea09",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">TMDA (Transportation Mode Detector and Analyzer)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200b16ca",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Introduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a568ac0",
   "metadata": {},
   "source": [
    "Transportation mode detection (TMD) is a well-known sub-task of a more general one called Human Activity Recognition (HAR), which aim to understand what activities a user is performing, through data produced during those activities.\n",
    "\n",
    "For this particular project only the classes bus, car, still, train and walking are considered to be a transportation mode, while data used to train a classifier comes from accelerometer and gyroscope sensors, read with a frequency of 20 Hz.\n",
    "\n",
    "To show more about a detection, location data (latitude and longitude) are also included, but not used in the training phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fccb359",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Motivations</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697cb39d",
   "metadata": {},
   "source": [
    "TMD can be used, for example, by public transport companies (such as FCE) to better understand how people move everyday, and improve their services if public transports are poorly used.\n",
    "\n",
    "For example, if bus are the less used among the others, a transport company can increse the quality of the service by increasing the number of run or cover a much greater area of a city and so on.\n",
    "\n",
    "This can potentially have a strong impact on the environment, reducing **CO2 emissions** and **pollution**, making a city more green."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b49510",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Workflow</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72988187",
   "metadata": {},
   "source": [
    "<img src=\"./workflow/WorkFlow.drawio.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e076db",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Data Acquisition</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7927b0",
   "metadata": {},
   "source": [
    "<img src=\"./img/phyphox.png\" width=\"100\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfacff9",
   "metadata": {},
   "source": [
    "Data are collected via the mobile app **Phyphox**, that allows to select sensors to read from and the reading frequency (in this case 20 Hz).\n",
    "\n",
    "Once the recording is started, sensors data are read and, at the end of it, can be exported as a zip file, containing one CSV for each sensors, plus metadata (such as time of recording and device used).\n",
    "\n",
    "A script in python will listen to a folder containing the above zip files and, when there is something to read, it will extract and merge sensors CSVs into one single CSV called **sensors.csv**.\n",
    "\n",
    "In **update_sensors_csv()** is also performed a filtering of sensors data older than 5 seconds from the start of the recording, so that only the first 5 seconds of reading for each sensors are kept.\n",
    "\n",
    "In future this could be an embedded function of the recording app. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "        # get a list of zip files\n",
    "        zip_list = glob.glob('*.zip') \n",
    "        # if is not empty, update sensors.csv, else sleep for 5 sec\n",
    "        if len(zip_list) > 0:\n",
    "            zf = get_earliest_zipfile(zip_list)\n",
    "            update_sensors_csv(zf)\n",
    "        sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e45c79",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef9a201",
   "metadata": {},
   "source": [
    "<img src=\"./img/spark_logo.png\" width=\"150\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91d537",
   "metadata": {},
   "source": [
    "<i>\"Apache Spark is a unified engine for large-scale data analytics, used to execute data engineering, data science, and machine learning on single-node machines or clusters.\"</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93d5e1d",
   "metadata": {},
   "source": [
    "We train a **Gradient-Boosted Tree** classification model with Spark MLlib, and then save it to disk for later use.\n",
    "\n",
    "At the end of the training, the accuracy was **72%**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ea2f0",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"./memes/nice.jpg\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61cf6bb",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Data Ingestion</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122eed02",
   "metadata": {},
   "source": [
    "<img src=\"./img/logstash_logo.svg\" width=\"100\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4fb6d1",
   "metadata": {},
   "source": [
    "<i>\"Logstash is a free and open server-side data processing pipeline that ingests data from a multitude of sources, transforms it, and then sends it to your favorite \"stash.\"\"</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251dbdb",
   "metadata": {},
   "source": [
    "Ingestion is provided by Logstash, that reads updated lines of the file **sensors.csv** and send them to a kafka topic called **sensors-raw**.\n",
    "\n",
    "That's it, thank you Logstash <3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ee29d",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"./memes/logstash_heaven.jpg\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6310e3ff",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Stream Processing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6525258",
   "metadata": {},
   "source": [
    "<img src=\"./img/stream_processing.png\" width=\"250\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5647d",
   "metadata": {},
   "source": [
    "<i>\"Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.\"</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f985cacf",
   "metadata": {},
   "source": [
    "A Kafka cluster is responsible for handling streams coming from Logstash and storing them efficientely to specific topics.\n",
    "\n",
    "Data are also replicated across different Kafka brokers, so if one of them goes down (temporarily or permanently) we don't lose any data.\n",
    "\n",
    "There are two main topics: **sensors-raw** (for data coming from Logstash) and **sensors** (for data cleaned by a Spark container) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c105db27",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Data Cleaning</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a7beb",
   "metadata": {},
   "source": [
    "<img src=\"./img/spark_logo.png\" width=\"150\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f9acc4",
   "metadata": {},
   "source": [
    "Before making any prediction, data must be cleaned, in order to extract features like **mean**, **min**, **max** and **stddev** in a 5 seconds time window. Here is the main function of data cleaning task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d99bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    df = df \\\n",
    "        .withColumn('acc', compute_magnitude(col('acc_x'), col('acc_y'), col('acc_z'))) \\\n",
    "        .withColumn('gyro', compute_magnitude(col('gyro_x'), col('gyro_y'), col('gyro_z'))) \\\n",
    "        .withWatermark('timestamp', '2 seconds') \\\n",
    "        .groupBy(\n",
    "            # after 2 sec of lacking data from a user we end the session\n",
    "            session_window('timestamp', '2 seconds'),\n",
    "            'user_id') \\\n",
    "        .agg(mean('acc').alias('acc_mean'),\n",
    "            min('acc').alias('acc_min'),\n",
    "            max('acc').alias('acc_max'),\n",
    "            stddev('acc').alias('acc_stddev'),\n",
    "            mean('gyro').alias('gyro_mean'),\n",
    "            min('gyro').alias('gyro_min'),\n",
    "            max('gyro').alias('gyro_max'),\n",
    "            stddev('gyro').alias('gyro_stddev'),\n",
    "            first('latitude').alias('latitude'),\n",
    "            first('longitude').alias('longitude')) \\\n",
    "        .withColumn('timestamp', col('session_window').getField('start')) \\\n",
    "        .na.fill(value=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8a3a5",
   "metadata": {},
   "source": [
    "We made use of a **session window**, but what is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb609cf4",
   "metadata": {},
   "source": [
    "<img src=\"./img/session_windows.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc516e78",
   "metadata": {},
   "source": [
    "<i>\"A session window begins with a single data point and broadens itself in case of the upcoming element has been collected inside of the gap period.\n",
    "When the last item is accepted, the session window ends when no items are acknowledged inside of the gap period.\"</i>\n",
    "\n",
    "Note that we can't control the dimension of a window, wich is determined by events themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2461edfe",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"./memes/session_window_5sec.jpg\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada0b4ab",
   "metadata": {},
   "source": [
    "Remember, in data acquisition phase, a function that takes only 5 seconds of data for each sensor was already applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee282f",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"./memes/normal_windows_why.jpg\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41760acf",
   "metadata": {},
   "source": [
    "I'll explain with a very simple example:\n",
    "\n",
    "If **user1** records at time **t** and **user2** at time **t+1**, a tumbling window is in the interval <b>[t, t+5]</b>.\n",
    "So at time **t+5** we do grouping without including the last second of user2 in this window.\n",
    "At the end we grouped 5 seconds for user1 and 4 seconds for user2.\n",
    "\n",
    "<u>We need to use session windows to have dedicated windows for each user</u>, beginning when events for that particular user occour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e24793",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"./memes/confusion.jpg\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02fe6e5",
   "metadata": {},
   "source": [
    "If you didn't understand, don't worry and take a look at this https://towardsdatascience.com/spark-3-2-session-windowing-feature-for-streaming-data-e404d92e267."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2717e1d",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Value Extraction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f2db1c",
   "metadata": {},
   "source": [
    "<img src=\"./img/spark_logo.png\" width=\"150\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6be54",
   "metadata": {},
   "source": [
    "Using the model created at the end of the training phase, we enrich our data with predictions on transportation mode, given a set of input features (extracted earlier).\n",
    "\n",
    "Once the predictions are made, we send the results to an Elasticsearch index called **sensors**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d7f3fa",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"./memes/tuning.jpg\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b046b7",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Data Indexing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f38b94",
   "metadata": {},
   "source": [
    "<img src=\"./img/elastic_search_logo.svg\" width=\"80\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a94ba5",
   "metadata": {},
   "source": [
    "<i>\"Elasticsearch is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. Known for its simple REST APIs, distributed nature, speed, and scalability, Elasticsearch is the central component of the Elastic Stack\".</i>\n",
    "\n",
    "Remember: **\"Elasticsearch is fast. Really, really fast\".**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512ee56",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"./memes/i_am_speed.jpg\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f43106",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Data Visualization</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1612f867",
   "metadata": {},
   "source": [
    "<img src=\"./img/kibana_logo.svg\" width=\"80\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bbb3fe",
   "metadata": {},
   "source": [
    "<i>\"Kibana is an free and open frontend application that sits on top of the Elastic Stack, providing search and data visualization capabilities for data indexed in Elasticsearch. Commonly known as the charting tool for the Elastic Stack\".</i>\n",
    "\n",
    "Finally we can visualize the results through charts realized with Kibana:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e8c9ef",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"./img/kibana_dashboard.png\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d49130d",
   "metadata": {},
   "source": [
    "## Why do we need these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a100e7e",
   "metadata": {},
   "source": [
    "## Thanks for your attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9064520d",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"./memes/we_did_it.gif\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aedcf5",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "Alessandro Resta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
